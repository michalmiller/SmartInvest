import httpx
from googletrans import Translator

OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL_NAME = "phi3"

translator = Translator()

async def call_ollama(prompt: str) -> str:
    payload = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": False
    }
    try:
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(OLLAMA_URL, json=payload)
            response.raise_for_status()
            result = response.json()
            return result.get("response", "[No response]")
    except Exception as e:
        return f"[ERROR: {e}]"

async def ask_llm(question: str) -> str:
    print(" 砖 砖:", question)

    # 转专 注专转 转
    #translated = translator.translate(question, src='he', dest='en')
   # translated_question = translated.text
    # print(" 砖 转专转:", translated_question)

    # 拽专 
    response_en = await call_ollama(question)
    print(" 转砖 转:", response_en)

    # 转专 专 注专转
    #translated = translator.translate(response_en, src='en', dest='he')
    #translated_answer = translated.text
    #print(" 转砖 转专转 注专转:", response_en)

    return response_en
